{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Molecular-VAE-final",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aksub99/molecular-vae/blob/master/Molecular_VAE_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ7Cl9tzTCl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "import gzip\n",
        "import pandas\n",
        "import h5py\n",
        "import numpy as np\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import h5py\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from sklearn import model_selection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aXdqRqQTLEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_array(i, n):\n",
        "    return map(int, [ix == i for ix in xrange(n)])\n",
        "\n",
        "def one_hot_index(vec, charset):\n",
        "    return map(charset.index, vec)\n",
        "\n",
        "def from_one_hot_array(vec):\n",
        "    oh = np.where(vec == 1)\n",
        "    if oh[0].shape == (0, ):\n",
        "        return None\n",
        "    return int(oh[0][0])\n",
        "\n",
        "def decode_smiles_from_indexes(vec, charset):\n",
        "    return \"\".join(map(lambda x: charset[x], vec)).strip()\n",
        "\n",
        "def load_dataset(filename, split = True):\n",
        "    h5f = h5py.File(filename, 'r')\n",
        "    if split:\n",
        "        data_train = h5f['data_train'][:]\n",
        "    else:\n",
        "        data_train = None\n",
        "    data_test = h5f['data_test'][:]\n",
        "    charset =  h5f['charset'][:]\n",
        "    h5f.close()\n",
        "    if split:\n",
        "        return (data_train, data_test, charset)\n",
        "    else:\n",
        "        return (data_test, charset)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGAirp3UUDmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MolecularVAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MolecularVAE, self).__init__()\n",
        "\n",
        "        self.conv_1 = nn.Conv1d(120, 9, kernel_size=9)\n",
        "        self.conv_2 = nn.Conv1d(9, 9, kernel_size=9)\n",
        "        self.conv_3 = nn.Conv1d(9, 10, kernel_size=11)\n",
        "        self.linear_0 = nn.Linear(70, 435)\n",
        "        self.linear_1 = nn.Linear(435, 292)\n",
        "        self.linear_2 = nn.Linear(435, 292)\n",
        "\n",
        "        self.linear_3 = nn.Linear(292, 292)\n",
        "        self.gru = nn.GRU(292, 501, 3, batch_first=True)\n",
        "        self.linear_4 = nn.Linear(501, 33)\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.relu(self.conv_1(x))\n",
        "        x = self.relu(self.conv_2(x))\n",
        "        x = self.relu(self.conv_3(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.selu(self.linear_0(x))\n",
        "        return self.linear_1(x), self.linear_2(x)\n",
        "\n",
        "    def sampling(self, z_mean, z_logvar):\n",
        "        epsilon = 1e-2 * torch.randn_like(z_logvar)\n",
        "        return torch.exp(0.5 * z_logvar) * epsilon + z_mean\n",
        "\n",
        "    def decode(self, z):\n",
        "        z = F.selu(self.linear_3(z))\n",
        "        z = z.view(z.size(0), 1, z.size(-1)).repeat(1, 120, 1)\n",
        "        output, hn = self.gru(z)\n",
        "        out_reshape = output.contiguous().view(-1, output.size(-1))\n",
        "        y0 = F.softmax(self.linear_4(out_reshape), dim=1)\n",
        "        y = y0.contiguous().view(output.size(0), -1, y0.size(-1))\n",
        "        return y\n",
        "\n",
        "    def forward(self, x):\n",
        "        z_mean, z_logvar = self.encode(x)\n",
        "        z = self.sampling(z_mean, z_logvar)\n",
        "        return self.decode(z), z_mean, z_logvar\n",
        "\n",
        "def vae_loss(x_decoded_mean, x, z_mean, z_logvar):\n",
        "    xent_loss = F.binary_cross_entropy(x_decoded_mean, x, size_average=False)\n",
        "    kl_loss = -0.5 * torch.sum(1 + z_logvar - z_mean.pow(2) - z_logvar.exp())\n",
        "    return xent_loss + kl_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psCpULS_AQMg",
        "colab_type": "code",
        "outputId": "a222d5e6-1e0b-46ca-9cf5-7bc70dfed870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "!rm -R 'molecular-vae'\n",
        "!git clone https://github.com/aksub99/molecular-vae.git\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('molecular-vae/data/processed.zip', 'r')\n",
        "zip_ref.extractall('molecular-vae/data/')\n",
        "zip_ref.close()\n",
        "\n",
        "!git clone https://aksub99:Ajak1999@github.com/aksub99/FissionNet.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'molecular-vae'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/55)\u001b[K\rremote: Counting objects:   3% (2/55)\u001b[K\rremote: Counting objects:   5% (3/55)\u001b[K\rremote: Counting objects:   7% (4/55)\u001b[K\rremote: Counting objects:   9% (5/55)\u001b[K\rremote: Counting objects:  10% (6/55)\u001b[K\rremote: Counting objects:  12% (7/55)\u001b[K\rremote: Counting objects:  14% (8/55)\u001b[K\rremote: Counting objects:  16% (9/55)\u001b[K\rremote: Counting objects:  18% (10/55)\u001b[K\rremote: Counting objects:  20% (11/55)\u001b[K\rremote: Counting objects:  21% (12/55)\u001b[K\rremote: Counting objects:  23% (13/55)\u001b[K\rremote: Counting objects:  25% (14/55)\u001b[K\rremote: Counting objects:  27% (15/55)\u001b[K\rremote: Counting objects:  29% (16/55)\u001b[K\rremote: Counting objects:  30% (17/55)\u001b[K\rremote: Counting objects:  32% (18/55)\u001b[K\rremote: Counting objects:  34% (19/55)\u001b[K\rremote: Counting objects:  36% (20/55)\u001b[K\rremote: Counting objects:  38% (21/55)\u001b[K\rremote: Counting objects:  40% (22/55)\u001b[K\rremote: Counting objects:  41% (23/55)\u001b[K\rremote: Counting objects:  43% (24/55)\u001b[K\rremote: Counting objects:  45% (25/55)\u001b[K\rremote: Counting objects:  47% (26/55)\u001b[K\rremote: Counting objects:  49% (27/55)\u001b[K\rremote: Counting objects:  50% (28/55)\u001b[K\rremote: Counting objects:  52% (29/55)\u001b[K\rremote: Counting objects:  54% (30/55)\u001b[K\rremote: Counting objects:  56% (31/55)\u001b[K\rremote: Counting objects:  58% (32/55)\u001b[K\rremote: Counting objects:  60% (33/55)\u001b[K\rremote: Counting objects:  61% (34/55)\u001b[K\rremote: Counting objects:  63% (35/55)\u001b[K\rremote: Counting objects:  65% (36/55)\u001b[K\rremote: Counting objects:  67% (37/55)\u001b[K\rremote: Counting objects:  69% (38/55)\u001b[K\rremote: Counting objects:  70% (39/55)\u001b[K\rremote: Counting objects:  72% (40/55)\u001b[K\rremote: Counting objects:  74% (41/55)\u001b[K\rremote: Counting objects:  76% (42/55)\u001b[K\rremote: Counting objects:  78% (43/55)\u001b[K\rremote: Counting objects:  80% (44/55)\u001b[K\rremote: Counting objects:  81% (45/55)\u001b[K\rremote: Counting objects:  83% (46/55)\u001b[K\rremote: Counting objects:  85% (47/55)\u001b[K\rremote: Counting objects:  87% (48/55)\u001b[K\rremote: Counting objects:  89% (49/55)\u001b[K\rremote: Counting objects:  90% (50/55)\u001b[K\rremote: Counting objects:  92% (51/55)\u001b[K\rremote: Counting objects:  94% (52/55)\u001b[K\rremote: Counting objects:  96% (53/55)\u001b[K\rremote: Counting objects:  98% (54/55)\u001b[K\rremote: Counting objects: 100% (55/55)\u001b[K\rremote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 165 (delta 21), reused 28 (delta 12), pack-reused 110\u001b[K\n",
            "Receiving objects: 100% (165/165), 2.93 MiB | 2.70 MiB/s, done.\n",
            "Resolving deltas: 100% (81/81), done.\n",
            "fatal: destination path 'FissionNet' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXR-wWN5bo_m",
        "colab_type": "code",
        "outputId": "b0e7c275-2a3c-4536-ce64-e5301d21766f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "data_train, data_test, charset = load_dataset('FissionNet/data/singlet_processed.h5')\n",
        "data_train = torch.utils.data.TensorDataset(torch.from_numpy(data_train))\n",
        "train_loader = torch.utils.data.DataLoader(data_train, batch_size=250, shuffle=True)\n",
        "\n",
        "data_test = torch.utils.data.TensorDataset(torch.from_numpy(data_test))\n",
        "test_loader = torch.utils.data.DataLoader(data_test, batch_size=250, shuffle=True)\n",
        "\n",
        "print(charset)\n",
        "print(len(charset))\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "epochs = 30\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ' '#' ')' '(' '+' '-' '1' '3' '2' '5' '4' '7' '6' '9' '8' '=' 'A' 'C'\n",
            " 'B' 'F' 'I' 'H' 'O' 'N' 'P' 'S' '[' ']' 'a' 'c' 'b' 'e' 'i' 'l' 'o' 'n'\n",
            " 's' 'r']\n",
            "38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svvyAk-_29ZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MolecularVAE().to(device)\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r0gV2l-AtAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "        data = data[0].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output, mean, logvar = model(data)\n",
        "        \n",
        "        if batch_idx==0:\n",
        "              inp = data.cpu().numpy()\n",
        "              outp = output.cpu().detach().numpy()\n",
        "              lab = data.cpu().numpy()\n",
        "              print(\"Input:\")\n",
        "              print(decode_smiles_from_indexes(map(from_one_hot_array, inp[0]), charset))\n",
        "              print(\"Label:\")\n",
        "              print(decode_smiles_from_indexes(map(from_one_hot_array, lab[0]), charset))\n",
        "              sampled = outp[0].reshape(1, 120, len(charset)).argmax(axis=2)[0]\n",
        "              print(\"Output:\")\n",
        "              print(decode_smiles_from_indexes(sampled, charset))\n",
        "        \n",
        "        loss = vae_loss(output, data, mean, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss\n",
        "        optimizer.step()\n",
        "#         if batch_idx % 100 == 0:\n",
        "#             print(f'{epoch} / {batch_idx}\\t{loss:.4f}')\n",
        "    print('train', train_loss / len(train_loader.dataset))\n",
        "    return train_loss / len(train_loader.dataset)\n",
        "  \n",
        "def test(epoch):\n",
        "  with torch.no_grad():\n",
        "      test_loss = 0.0\n",
        "      for batch_idx, data in enumerate(test_loader):\n",
        "          data = data[0].to(device)\n",
        "          output, mean, logvar = model(data)\n",
        "          loss = vae_loss(output, data, mean, logvar)\n",
        "          test_loss += loss\n",
        "      print('test', test_loss / len(test_loader.dataset))\n",
        "      return test_loss / len(test_loader.dataset)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwATprps-hu3",
        "colab_type": "code",
        "outputId": "6bcfdb18-a144-4ce6-e182-07c06fee8ecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1if7E0S-mYo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3054ed09-f486-4e8f-c4f1-dcef6ee47728"
      },
      "source": [
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "train_loss_values = []\n",
        "test_loss_values = []\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss = train(epoch)\n",
        "    test_loss = test(epoch)\n",
        "    train_loss_values.append(train_loss)\n",
        "    test_loss_values.append(test_loss)\n",
        "    \n",
        "    if epoch % 2 == 0:\n",
        "        torch.save(model.state_dict(), \"drive/My Drive/chembl/singlet_{}.pth\".format(epoch))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(np.array(train_loss_values), 'r')\n",
        "plt.plot(np.array(test_loss_values), 'b')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:\n",
            "Cc1cc(C)c(c(C)c1)C(=C=C=C=C=C=C=C(c1c(C)cc(C)cc1C)c1c(C)cc(C)cc1C)c1c(C)cc(C)cc1C\n",
            "Label:\n",
            "Cc1cc(C)c(c(C)c1)C(=C=C=C=C=C=C=C(c1c(C)cc(C)cc1C)c1c(C)cc(C)cc1C)c1c(C)cc(C)cc1C\n",
            "Output:\n",
            "Fi)))))PAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train tensor(552.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(420.3666, device='cuda:0')\n",
            "Input:\n",
            "CC(C)(C)C(=CC=CC=CC=C(C#N)C#N)C(C)(C)C\n",
            "Label:\n",
            "CC(C)(C)C(=CC=CC=CC=C(C#N)C#N)C(C)(C)C\n",
            "Output:\n",
            "1)11)1)===))))))c)))))cc)c))))cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc\n",
            "train tensor(397.6053, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(322.5053, device='cuda:0')\n",
            "Input:\n",
            "COc1ccc(cc1)C#Cc1c2ccccc2c(C#Cc2ccc(OC)cc2)c2c(c3ccccc3)c3ccccc3c(c3ccccc3)c12\n",
            "Label:\n",
            "COc1ccc(cc1)C#Cc1c2ccccc2c(C#Cc2ccc(OC)cc2)c2c(c3ccccc3)c3ccccc3c(c3ccccc3)c12\n",
            "Output:\n",
            "=  cc1c==cO)))ccccccccccccc\n",
            "train tensor(319.7636, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(313.0934, device='cuda:0')\n",
            "Input:\n",
            "OC(=O)C1=[N+]([N-]OC1=O)c1ccccc1\n",
            "Label:\n",
            "OC(=O)C1=[N+]([N-]OC1=O)c1ccccc1\n",
            "Output:\n",
            "111cccccccccccccccccccccccc\n",
            "train tensor(315.7901, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(302.1194, device='cuda:0')\n",
            "Input:\n",
            "CCN(CC)P1(=O)OCC2OCC(=O)C2O1\n",
            "Label:\n",
            "CCN(CC)P1(=O)OCC2OCC(=O)C2O1\n",
            "Output:\n",
            "c1cccccccccccccccccccccccccc\n",
            "train tensor(301.9131, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(288.4203, device='cuda:0')\n",
            "Input:\n",
            "O=C1c2ccccc2[N+](=C1c1cccc[n+]1[O-])[O-]\n",
            "Label:\n",
            "O=C1c2ccccc2[N+](=C1c1cccc[n+]1[O-])[O-]\n",
            "Output:\n",
            "ccccccccccccccccccccccccccccccccc\n",
            "train tensor(289.0208, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(282.5010, device='cuda:0')\n",
            "Input:\n",
            "O=C1C=C2OCOC2=CC1=CC=Cc1ccccc1\n",
            "Label:\n",
            "O=C1C=C2OCOC2=CC1=CC=Cc1ccccc1\n",
            "Output:\n",
            "cccccccccccccccccccccccccccccccccc\n",
            "train tensor(282.3469, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(273.2106, device='cuda:0')\n",
            "Input:\n",
            "O=Nc1c(OCc2ccccc2)nc(NCc2ccccc2)nc1OCc1ccccc1\n",
            "Label:\n",
            "O=Nc1c(OCc2ccccc2)nc(NCc2ccccc2)nc1OCc1ccccc1\n",
            "Output:\n",
            "ccccccccccccccccccccccccccccccccccccccc\n",
            "train tensor(272.6410, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(262.9565, device='cuda:0')\n",
            "Input:\n",
            "FC(F)(F)c1ccc(cc1)C1=C2C(=O)N(Cc3ccccc3)C(=C2C(=O)N1Cc1ccccc1)c1ccc(cc1)C(F)(F)F\n",
            "Label:\n",
            "FC(F)(F)c1ccc(cc1)C1=C2C(=O)N(Cc3ccccc3)C(=C2C(=O)N1Cc1ccccc1)c1ccc(cc1)C(F)(F)F\n",
            "Output:\n",
            "Cccccccccccccccccccccccccccccccccccccccccccccc\n",
            "train tensor(263.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(254.3046, device='cuda:0')\n",
            "Input:\n",
            "C[Si](C)(C)C1=CC=C(S1)C(=C=C=C(C1=CC=C(S1)[Si](C)(C)C)C1=CC=C(S1)[Si](C)(C)C)C1=CC=C(S1)[Si](C)(C)C\n",
            "Label:\n",
            "C[Si](C)(C)C1=CC=C(S1)C(=C=C=C(C1=CC=C(S1)[Si](C)(C)C)C1=CC=C(S1)[Si](C)(C)C)C1=CC=C(S1)[Si](C)(C)C\n",
            "Output:\n",
            "CCCCCCCCCccCccccCccccccccccccccccccccccccccccccccccc\n",
            "train tensor(254.3533, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(245.4980, device='cuda:0')\n",
            "Input:\n",
            "O=Nc1c(OCc2ccccc2)nc(NCc2ccccc2)nc1OCc1ccccc1\n",
            "Label:\n",
            "O=Nc1c(OCc2ccccc2)nc(NCc2ccccc2)nc1OCc1ccccc1\n",
            "Output:\n",
            "CCCCCCCCCCCCCcCcccccccccccccccccccccccccccccccc\n",
            "train tensor(245.1518, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(241.5479, device='cuda:0')\n",
            "Input:\n",
            "CCCCC(CC)CN1C(=O)C2=C(N(CC(CC)CCCC)C(=O)C2=C1C1=CC=C(S1)c1ccccc1)C1=CC=C(S1)c1ccccc1\n",
            "Label:\n",
            "CCCCC(CC)CN1C(=O)C2=C(N(CC(CC)CCCC)C(=O)C2=C1C1=CC=C(S1)c1ccccc1)C1=CC=C(S1)c1ccccc1\n",
            "Output:\n",
            "CCCCCCCCCCCCCCCCCCCCCCCCCCCcccccccccccccccccccccccccccccCCCCCcccccc\n",
            "train tensor(240.8309, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(238.4209, device='cuda:0')\n",
            "Input:\n",
            "CC(C)[Si](C#Cc1c2ccccc2c(C#C[Si](C(C)C)(C(C)C)C(C)C)c2nc3ccccc3cc12)(C(C)C)C(C)C\n",
            "Label:\n",
            "CC(C)[Si](C#Cc1c2ccccc2c(C#C[Si](C(C)C)(C(C)C)C(C)C)c2nc3ccccc3cc12)(C(C)C)C(C)C\n",
            "Output:\n",
            "CCCCCCCCCCCCCCCCCCCCcccccccccccccccccccccccccccccccccccccccccccccc\n",
            "train tensor(237.5828, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(236.8291, device='cuda:0')\n",
            "Input:\n",
            "Brc1ccc(cc1)C1=C2C(=O)N(Cc3ccccc3)C(=C2C(=O)N1Cc1ccccc1)c1ccc(Br)cc1\n",
            "Label:\n",
            "Brc1ccc(cc1)C1=C2C(=O)N(Cc3ccccc3)C(=C2C(=O)N1Cc1ccccc1)c1ccc(Br)cc1\n",
            "Output:\n",
            "CCCCCCCCCCCCCCCCCcccccccccccccccccccccccccccccccccccccccccccccc\n",
            "train tensor(236.2822, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(237.0217, device='cuda:0')\n",
            "Input:\n",
            "N(c1ccccc1)c1ccc2N=C3C=C(Nc4ccccc4)C(C=C3N(c3ccccc3)c2c1)=Nc1ccccc1\n",
            "Label:\n",
            "N(c1ccccc1)c1ccc2N=C3C=C(Nc4ccccc4)C(C=C3N(c3ccccc3)c2c1)=Nc1ccccc1\n",
            "Output:\n",
            "CCCCCCCCcccCCCCCCcccccccccccccccccccccccccccccccccccccccccccc\n",
            "train tensor(235.7534, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(233.9405, device='cuda:0')\n",
            "Input:\n",
            "[O-][N+](C1=CCC2(CC1)OCCO2)=C1c2ccccc2c2ccccc12\n",
            "Label:\n",
            "[O-][N+](C1=CCC2(CC1)OCCO2)=C1c2ccccc2c2ccccc12\n",
            "Output:\n",
            "CCCCCccccccCCccccccccccccccccccccccccccccccccccccccc\n",
            "train tensor(232.4173, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(231.1046, device='cuda:0')\n",
            "Input:\n",
            "Cc1ccc(cc1)N=C1N(c2ccc(C)cc2)C(c2ccccc12)=C1N(c2ccc(C)cc2)C(c2ccccc12)=C(C#N)C#N\n",
            "Label:\n",
            "Cc1ccc(cc1)N=C1N(c2ccc(C)cc2)C(c2ccccc12)=C1N(c2ccc(C)cc2)C(c2ccccc12)=C(C#N)C#N\n",
            "Output:\n",
            "CCCCCCCCCccCCCccccccccccccccccccccccccccccccccccccccccccccccccccccccc\n",
            "train tensor(229.3754, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(228.0196, device='cuda:0')\n",
            "Input:\n",
            "CN1C=CC(=C1)C1=C(C=C(C2=[N+]([O-])ON=C12)N(=O)=O)N(=O)=O\n",
            "Label:\n",
            "CN1C=CC(=C1)C1=C(C=C(C2=[N+]([O-])ON=C12)N(=O)=O)N(=O)=O\n",
            "Output:\n",
            "CCCCCCCCCCCCCCCCCCccccccccccccccccccccccccccccccccccccccccc\n",
            "train tensor(226.4003, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(224.5679, device='cuda:0')\n",
            "Input:\n",
            "FC(F)(F)c1ccc2C(=O)C(Nc2c1)=C1Nc2cc(ccc2C1=O)C(F)(F)F\n",
            "Label:\n",
            "FC(F)(F)c1ccc2C(=O)C(Nc2c1)=C1Nc2cc(ccc2C1=O)C(F)(F)F\n",
            "Output:\n",
            "CCCCccCcCcCCCCcccccccccccccccccccccccccccccccccccccc\n",
            "train tensor(223.2915, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(222.3030, device='cuda:0')\n",
            "Input:\n",
            "C[Si](C)(C)N(P=PN(N([Si](C)(C)C)[Si](C)(C)C)[Si](C)(C)C)N([Si](C)(C)C)[Si](C)(C)C\n",
            "Label:\n",
            "C[Si](C)(C)N(P=PN(N([Si](C)(C)C)[Si](C)(C)C)[Si](C)(C)C)N([Si](C)(C)C)[Si](C)(C)C\n",
            "Output:\n",
            "CCCCCcCcCcCCCCCccccccccccccccccccccccccccccccccccccccccccccccc\n",
            "train tensor(221.0971, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(219.9189, device='cuda:0')\n",
            "Input:\n",
            "CCC1=CC=C(N1)C1=C2C=CC(=[N+]2[B-](F)(F)N2N=NN=C12)CC\n",
            "Label:\n",
            "CCC1=CC=C(N1)C1=C2C=CC(=[N+]2[B-](F)(F)N2N=NN=C12)CC\n",
            "Output:\n",
            "CCCCCCCCCCCCCCCCCcccccccccccccccccccccccccccccccccc\n",
            "train tensor(218.8640, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(217.7369, device='cuda:0')\n",
            "Input:\n",
            "O=C1C(Nc2ccc(cc12)c1ccccc1)=C1Nc2ccc(cc2C1=O)c1ccccc1\n",
            "Label:\n",
            "O=C1C(Nc2ccc(cc12)c1ccccc1)=C1Nc2ccc(cc2C1=O)c1ccccc1\n",
            "Output:\n",
            "CCCCCcccccCCCCccccccccccccccccccccccccccccccccccccc\n",
            "train tensor(216.8715, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(215.9898, device='cuda:0')\n",
            "Input:\n",
            "CCOC(=O)C12ON=C(c3ccccc3)C31N=NCN3N1CC21\n",
            "Label:\n",
            "CCOC(=O)C12ON=C(c3ccccc3)C31N=NCN3N1CC21\n",
            "Output:\n",
            "CCCCCcCCcCCcCCcCcCcccccccccccccccccccccc\n",
            "train tensor(214.9923, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(214.7344, device='cuda:0')\n",
            "Input:\n",
            "CCCCCCN1C(=O)C2=C(N(CCCCCC)C(=O)C2=C1C1=CC=C(Br)S1)C1=CC=C(Br)S1\n",
            "Label:\n",
            "CCCCCCN1C(=O)C2=C(N(CCCCCC)C(=O)C2=C1C1=CC=C(Br)S1)C1=CC=C(Br)S1\n",
            "Output:\n",
            "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
            "train tensor(213.5979, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(213.3497, device='cuda:0')\n",
            "Input:\n",
            "CCCCCCC1=CC=C(S1)c1c2cc3ccccc3cc2c(C2=CC=C(CCCCCC)S2)c2cc3ccccc3cc12\n",
            "Label:\n",
            "CCCCCCC1=CC=C(S1)c1c2cc3ccccc3cc2c(C2=CC=C(CCCCCC)S2)c2cc3ccccc3cc12\n",
            "Output:\n",
            "CCCCCCCCCCCCCCCCCCccccccccccccccccccccccccccccccccccccccccccccccccccccc\n",
            "train tensor(212.1754, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(211.7492, device='cuda:0')\n",
            "Input:\n",
            "O=C1N(Cc2ccccc2)C(=C2C(=O)N(Cc3ccccc3)C(=C12)C1=CC=CO1)C1=CC=CO1\n",
            "Label:\n",
            "O=C1N(Cc2ccccc2)C(=C2C(=O)N(Cc3ccccc3)C(=C12)C1=CC=CO1)C1=CC=CO1\n",
            "Output:\n",
            "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCccccccccccccccccccccccccccc\n",
            "train tensor(210.8340, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(210.1873, device='cuda:0')\n",
            "Input:\n",
            "CCOC(=O)C1=C(C)C(=C(N1)C=C1NC(=CC2=NC(=CC3=C(C)C(=C(N3)C(=O)OCC)C)C(=C2C)C)C(=C1C)C)C\n",
            "Label:\n",
            "CCOC(=O)C1=C(C)C(=C(N1)C=C1NC(=CC2=NC(=CC3=C(C)C(=C(N3)C(=O)OCC)C)C(=C2C)C)C(=C1C)C)C\n",
            "Output:\n",
            "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC\n",
            "train tensor(209.5577, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(209.3969, device='cuda:0')\n",
            "Input:\n",
            "COc1ccc(cc1)[N+]1=NOC(=C1C1=Nc2ccccc2S1)[O-]\n",
            "Label:\n",
            "COc1ccc(cc1)[N+]1=NOC(=C1C1=Nc2ccccc2S1)[O-]\n",
            "Output:\n",
            "CCCCccccccccccccccccccccccccccccccccccccc\n",
            "train tensor(208.6208, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(208.4201, device='cuda:0')\n",
            "Input:\n",
            "O=C1c2ccccc2[N+](=C1c1cccc[n+]1[O-])[O-]\n",
            "Label:\n",
            "O=C1c2ccccc2[N+](=C1c1cccc[n+]1[O-])[O-]\n",
            "Output:\n",
            "CCCcccccccccccccccccccccccccccccccccc\n",
            "train tensor(207.6537, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(207.3667, device='cuda:0')\n",
            "Input:\n",
            "CCOC(=O)C1=C2C=CC=CC2=C(N1)C(=C1N=C(C(=O)OCC)c2ccccc12)c1c(F)c(F)c(F)c(F)c1F\n",
            "Label:\n",
            "CCOC(=O)C1=C2C=CC=CC2=C(N1)C(=C1N=C(C(=O)OCC)c2ccccc12)c1c(F)c(F)c(F)c(F)c1F\n",
            "Output:\n",
            "CCCCCCCCCCCCCCCCCCCccCCCCCCCCCCCcccccccccccccccccccccccccccccccccccccccc\n",
            "train tensor(206.6841, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "test tensor(206.6664, device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3cf578d7d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noBcRibn/D3tl+az07Ku6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_B5mtTpIJTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(np.array(train_loss_values), 'r')\n",
        "plt.plot(np.array(test_loss_values), 'b')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7R7Ylo7_2Tf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "0c568de1-5af1-4c99-970c-86e5bc385678"
      },
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = MolecularVAE().to(device)\n",
        "model.load_state_dict(torch.load(\"drive/My Drive/molecular-vae/chembl_50k_80.pth\"))\n",
        "\n",
        "child_counter = 0\n",
        "for child in model.children():\n",
        "  print(\"child {}\".format(child_counter))\n",
        "  print(child)\n",
        "  child_counter+=1\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "child 0\n",
            "Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
            "child 1\n",
            "Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
            "child 2\n",
            "Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
            "child 3\n",
            "Linear(in_features=70, out_features=435, bias=True)\n",
            "child 4\n",
            "Linear(in_features=435, out_features=292, bias=True)\n",
            "child 5\n",
            "Linear(in_features=435, out_features=292, bias=True)\n",
            "child 6\n",
            "Linear(in_features=292, out_features=292, bias=True)\n",
            "child 7\n",
            "GRU(292, 501, num_layers=3, batch_first=True)\n",
            "child 8\n",
            "Linear(in_features=501, out_features=33, bias=True)\n",
            "child 9\n",
            "ReLU()\n",
            "child 10\n",
            "Softmax(dim=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzx2RfjiJTG_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "7266c0bf-d870-41b6-e3ae-317723aac7f7"
      },
      "source": [
        "class FissionNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FissionNet, self).__init__()\n",
        "    model = MolecularVAE()\n",
        "    model.load_state_dict(torch.load(\"drive/My Drive/molecular-vae/chembl_50k_80.pth\"))\n",
        "    self.conv_1 = list(model.children())[0]\n",
        "    self.conv_2 = list(model.children())[1]\n",
        "    self.conv_3 = list(model.children())[2]\n",
        "    self.linear_0 = nn.Linear(120, 435)\n",
        "    self.linear_1 = list(model.children())[4]\n",
        "    self.linear_2 = list(model.children())[5]\n",
        "    self.linear_3 = list(model.children())[6]\n",
        "    self.gru = list(model.children())[7]\n",
        "    self.linear_4 = nn.Linear(501, 38)\n",
        "    self.relu = list(model.children())[9]\n",
        "    self.softmax = list(model.children())[10]\n",
        "    \n",
        "  def encode(self, x):\n",
        "    x = self.relu(self.conv_1(x))\n",
        "    x = self.relu(self.conv_2(x))\n",
        "    x = self.relu(self.conv_3(x))\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = F.selu(self.linear_0(x))\n",
        "    return self.linear_1(x), self.linear_2(x)\n",
        "  \n",
        "  def sampling(self, z_mean, z_logvar):\n",
        "    epsilon = 1e-2 * torch.randn_like(z_logvar)\n",
        "    return torch.exp(0.5 * z_logvar) * epsilon + z_mean\n",
        "  \n",
        "  def decode(self, z):\n",
        "    z = F.selu(self.linear_3(z))\n",
        "    z = z.view(z.size(0), 1, z.size(-1)).repeat(1, 120, 1)\n",
        "    output, hn = self.gru(z)\n",
        "    out_reshape = output.contiguous().view(-1, output.size(-1))\n",
        "    y0 = F.softmax(self.linear_4(out_reshape), dim=1)\n",
        "    y = y0.contiguous().view(output.size(0), -1, y0.size(-1))\n",
        "    return y\n",
        "\n",
        "  def forward(self, x):\n",
        "    z_mean, z_logvar = self.encode(x)\n",
        "    z = self.sampling(z_mean, z_logvar)\n",
        "    return self.decode(z), z_mean, z_logvar  \n",
        "  \n",
        "model = FissionNet().to(device)\n",
        "\n",
        "child_counter = 0;\n",
        "for child in model.children():\n",
        "  print(\"child {}\".format(child_counter))\n",
        "  print(child)\n",
        "  child_counter+=1\n",
        "  \n",
        "child_counter = 0\n",
        "for child in model.children():\n",
        "  if child_counter != 3 and child_counter != 8:\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = False\n",
        "  child_counter+=1"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "child 0\n",
            "Conv1d(120, 9, kernel_size=(9,), stride=(1,))\n",
            "child 1\n",
            "Conv1d(9, 9, kernel_size=(9,), stride=(1,))\n",
            "child 2\n",
            "Conv1d(9, 10, kernel_size=(11,), stride=(1,))\n",
            "child 3\n",
            "Linear(in_features=120, out_features=435, bias=True)\n",
            "child 4\n",
            "Linear(in_features=435, out_features=292, bias=True)\n",
            "child 5\n",
            "Linear(in_features=435, out_features=292, bias=True)\n",
            "child 6\n",
            "Linear(in_features=292, out_features=292, bias=True)\n",
            "child 7\n",
            "GRU(292, 501, num_layers=3, batch_first=True)\n",
            "child 8\n",
            "Linear(in_features=501, out_features=38, bias=True)\n",
            "child 9\n",
            "ReLU()\n",
            "child 10\n",
            "Softmax(dim=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXF4N3i3Z0EB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
